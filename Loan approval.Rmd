
This rmd file contains multiple chunks of codes, when you run you may want to clear the environment every time you run different models

```{r Clustering} 
library(parallel)
library(ClusterR)
library(factoextra)
library(dplyr)
library(data.table)
```

```{r Clustering data reading}
# use fread to read data
fin_df <- fread("financial_risk_analysis_large.csv")

str(fin_df)
tail(fin_df)
```
```{r select numeric}
# Check for non-numeric columns
# numeric dataframe selection
numeric_cols <- names(fin_df)[sapply(fin_df, is.numeric)]
cat("num of numeric vectors cols：", length(numeric_cols), "\n")

# subset numeric data
fin_df_numeric <- fin_df[, ..numeric_cols]

# double check
str(fin_df_numeric)
```
```{r NA handling}
# check NAs
cat("IS THERE NAs？", anyNA(fin_df_numeric), "\n")

# Mean fill NAs
if (anyNA(fin_df_numeric)) {
  fin_df_numeric <- fin_df_numeric %>%
    mutate(across(everything(), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))
}

# Check no NAs left
cat("IS THERE NAs？", anyNA(fin_df_numeric), "\n")
```
```{r data preprocessing}
fin_df_scaled <- scale(fin_df_numeric)
fin_df_scaled <- as.data.frame(fin_df_scaled)
```
```{r see standardization}
#str(fin_df_scaled)
summary(fin_df_scaled)
```
```{r matrix}
#pca_result <- prcomp(fin_df_scaled, center = TRUE, scale. = TRUE)
#fin_df_pca <- pca_result$x[, 1:5]  # keep first 5 pricinple component
# use fin_df_scaled if not PCA

fin_df_pca_matrix <- as.matrix(fin_df_scaled)
```
```{r sampling}
set.seed(123)  # reprodcutivity
sample_percentage <- 0.01
sample_size <- floor(sample_percentage * nrow(fin_df_pca_matrix))
sample_size <- max(sample_size, 1000) # at least 10000 sample

cat("1% sample size:", sample_size, "\n")

sample_indices <- sample(1:nrow(fin_df_pca_matrix), size = sample_size, replace = FALSE)
fin_df_sample_1pct <- fin_df_pca_matrix[sample_indices, ]

# check if inf exit
if (any(!is.finite(fin_df_sample_1pct))) {
  cat("deleting inf...\n")
  fin_df_sample_1pct <- fin_df_sample_1pct[apply(fin_df_sample_1pct, 1, function(x) all(is.finite(x))), ]
}

# delete duplicated
duplicated_rows_sample <- sum(duplicated(fin_df_sample_1pct))
if (duplicated_rows_sample > 0) {
  cat("deleting duplicates...\n")
  fin_df_sample_1pct <- unique(fin_df_sample_1pct)
}
cat("final sample number of rows", nrow(fin_df_sample_1pct), "\n")
```
```{r check dataset variance}
#scaled data should have mean close to 0 and var close to 1。
summary(fin_df_sample_1pct)
apply(fin_df_sample_1pct, 2, var)
```
```{r Hierarchical}

# euclidean by default or manhattan
d <- dist(fin_df_sample_1pct, method = "euclidean")

# 2.  ward.D2 
hc <- hclust(d, method = "ward.D2")

# 3. Dendrogram
plot(hc, labels = FALSE, main = "Hierarchical Clustering Dendrogram", xlab = "", sub = "")

# 4. chose k 
k <- 5  # educated guess 5
rect.hclust(hc, k = k, border = "red")
```
```{r elbow method check}
# cluster height calc
merge_heights <- rev(hc$height)

# plot it
plot(1:length(merge_heights), merge_heights, type = "b",
     main = "Elbow Method for Hierarchical Clustering",
     xlab = "Number of Clusters", ylab = "Height")
```
```{r zoom in elbow}
# keep from 2 to 20
merge_heights_subset <- merge_heights[1:20]

# plot elbow
plot(2:(length(merge_heights_subset) + 1), merge_heights_subset, type = "b",
     main = "Elbow Method for Hierarchical Clustering",
     xlab = "Number of Clusters", ylab = "Height")
```
```{r plot k=5 Again}
# tree plot again
plot(hc, labels = FALSE, main = "Hierarchical Clustering Dendrogram",
     xlab = "", sub = "")

rect.hclust(hc, k = 5, border = "red")  # k=5
```
```{r check if Cluster is balanced}
# extract each cluster 
cluster_labels <- cutree(hc, k = 5)

# check result
table(cluster_labels)

# add result to original cluster
#fin_df_with_clusters <- cbind(fin_df_sample_1pct, Cluster = cluster_labels)
#head(fin_df_with_clusters)
```
```{r Inter-Cluster Separation Silhouette}
library(cluster)

d <- dist(fin_df_sample_1pct, method = "manhattan")
sil <- silhouette(cluster_labels, d)
mean_silhouette <- mean(sil[, 3])
cat("Mean Silhouette Coefficient:", mean_silhouette, "\n")
```
```{r tree_depth}
tree_depth <- max(hc$height)
cat("Tree Depth:", tree_depth, "\n")
```
```{r cophenetic}
cophenetic_dist <- cophenetic(hc)
correlation <- cor(d, cophenetic_dist)
cat("Cophenetic Correlation Coefficient:", correlation, "\n")
```
```{r aggregate features}
aggregate(fin_df_sample_1pct, by = list(Cluster = cluster_labels), FUN = mean)
```

```{r 3d plot with legend}
library(plotly)

# Add meaningful cluster labels
pca_fin_df$Cluster <- factor(cluster_labels, labels = c(
  "Premium Customers",
  "Low-Income, Low-Risk Group",
  "High-Debt, High-Income Group",
  "Medium-Risk Group",
  "Stable Savers"
))

# Create a 3D scatter plot with updated cluster labels
p <- plot_ly(
  pca_fin_df, 
  x = ~PC1, 
  y = ~PC2, 
  z = ~PC3, 
  color = ~Cluster,  # Use the updated Cluster labels
  type = "scatter3d", 
  mode = "markers"
) %>%
  layout(
    title = "3D Cluster Visualization",
    legend = list(title = list(text = "Customer Segments")),  # Update legend title
    scene = list(
      xaxis = list(title = "Principal Component 1"),
      yaxis = list(title = "Principal Component 2"),
      zaxis = list(title = "Principal Component 3")
    )
  )

# View the plot
p
```
```{r save html}
htmlwidgets::saveWidget(p, "plotly_3d.html")
```


```{r tree}
library(tree)
library(ISLR)
#read file

fin_df <- read.csv("financial_risk_analysis_large.csv")

#set different sample
set.seed(1)
sample(1:nrow(fin_df), 0.7 * nrow(fin_df)) -> training #Dynamically selects 70% of rows 
sample(1:1000,900) -> training_r #randomly

#pick variables may influence loan approval
data_tree <- fin_df[c("CreditScore", "DebtToIncomeRatio", "SavingsAccountBalance", 
                 "PaymentHistory", "EmploymentStatus", "LoanPurpose", 
                 "Age", "EducationLevel", "LoanApproval"),]


data_tree <- na.omit(data_tree) #ignore na value
data_tree$LoanApproval <- as.factor(data_tree$LoanApproval) #switch to factor

#plot randome select 70% one
tree(CreditScore~., data=fin_df, subset = training) -> d.tree
summary(d.tree)

plot(d.tree,type=c("uniform"))
text(d.tree)

#plot randome select 900
tree(CreditScore~., data=fin_df, subset = training_r) -> d.tree.r
summary(d.tree.r)

plot(d.tree.r,type=c("uniform"))
text(d.tree.r)

```

```{r KNN}
#### KNN #########
###### k-nearest neighbor (KNN)

# dataset
data <- read.csv("financial_risk_analysis_large.csv")

# choose variable
fin_df <- data[, c("CreditScore", "AnnualIncome", "LoanAmount", "LoanDuration",
                           "DebtToIncomeRatio", "SavingsAccountBalance", 
                           "LoanApproved")]

# replace na
fin_df <- na.omit(fin_df)

# 
numeric_columns <- c("CreditScore", "AnnualIncome", "LoanAmount", "LoanDuration",
                      "DebtToIncomeRatio", "SavingsAccountBalance")
fin_df[numeric_columns] <- scale(fin_df[numeric_columns])

# factor
fin_df$LoanApproved <- as.factor(fin_df$LoanApproved)

# 75% as training data, 25% as testing data
set.seed(123)
train_index <- sample(1:nrow(fin_df), 0.75 * nrow(fin_df))
train_data <- fin_df[train_index, ]
test_data <- fin_df[-train_index, ]

train_X <- train_data[, -which(names(train_data) == "LoanApproved")]
train_Y <- train_data$LoanApproved
test_X <- test_data[, -which(names(test_data) == "LoanApproved")]
test_Y <- test_data$LoanApproved

# 
library(class)

# K=3 
knn_pred_k3 <- knn(train = train_X, test = test_X, cl = train_Y, k = 3)
knn_pred_k3

library(caret)
confusion_matrix_k3 <- confusionMatrix(knn_pred_k3, test_Y)
print(confusion_matrix_k3)

# K=5 
knn_pred_k5 <- knn(train = train_X, test = test_X, cl = train_Y, k = 5)
knn_pred_k5

confusion_matrix_k5 <- confusionMatrix(knn_pred_k5, test_Y)
print(confusion_matrix_k5)

# K=7 
knn_pred_k7 <- knn(train = train_X, test = test_X, cl = train_Y, k = 7)
knn_pred_k7

confusion_matrix_k7 <- confusionMatrix(knn_pred_k7, test_Y)
print(confusion_matrix_k7)

# compare
cat("Accuracy with k=3: ", confusion_matrix_k3$overall["Accuracy"], "\n")
cat("Accuracy with k=5: ", confusion_matrix_k5$overall["Accuracy"], "\n")
cat("Accuracy with k=7: ", confusion_matrix_k7$overall["Accuracy"], "\n")

```

```{r linear regression}
library(MASS)
#setwd("~/Desktop/W-Data Analytics/Data Sets")
fin_df <- read.csv("financial_risk_analysis_large.csv")

### Filter data with loanApproved=1, and remove the loanApproved column ###
# filter data with approved loans
fin_df_approved <- fin_df[fin_df$LoanApproved == 1, ]
unique(fin_df_approved$LoanApproved) #check the filtering worked

# remove the LoanApproved column
fin_df_approved <- fin_df_approved[, !names(fin_df_approved) %in% "LoanApproved"] 
head(fin_df_approved)

# keep only numeric columns
fin_df_approved <- fin_df_approved[, sapply(fin_df_approved, is.numeric)]
str(fin_df_approved) #check the structure of the dataset

# check missing values
sum(is.na(fin_df_approved))

### Linear Regression ###
lm1 <- lm(CreditScore ~ ., data = fin_df_approved)
summary(lm1)


#### Model Selection ####
library(leaps)
# forward
regsubsets(CreditScore~., data = fin_df_approved, nvmax = 6, really.big = T, method = "forward") -> reg.sub.f
summary(reg.sub.f)

# backward
regsubsets(CreditScore~., data = fin_df_approved, nvmax = 6, really.big = T, method = "backward") -> reg.sub.b
summary(reg.sub.b)

# identify the model with the highest adjusted R^2 
summary(reg.sub.f) -> summary.f
which.max(summary.f$adjr2)

summary(reg.sub.b) -> summary.b
which.max(summary.b$adjr2)

# subset selection based on number of variables : 6
coef(reg.sub.f, 6)
coef(reg.sub.b, 6)

# New linear model with selected 6 variables
lm2 <- lm(CreditScore ~ CreditCardUtilizationRate + InterestRate + 
                    AutoLoanBalance + PersonalLoanBalance + OtherInsurancePolicies + MonthlyHousingCosts, 
                  data = fin_df_approved)
summary(lm2)

```

```{r Logistic Regression}

####### Logistic Regression ######
#setwd('C:/Users/louis/OneDrive/桌面/Data Analytics/Project')

fin_dt <- read.csv("financial_risk_analysis_large.csv")
View(fin_dt)

if (!requireNamespace("bestglm", quietly = TRUE)) {
  install.packages("bestglm")
}

options(max.print = 10000)

attach(fin_dt)
library(leaps)

n <- nrow(fin_dt)
size <- floor(0.75* n)

set.seed(1)

indices <- sample(1:n, size)
indices
train <- fin_dt[indices, ]
test <- fin_dt[-indices, ]  

nrow(train)
nrow(test)


names(fin_dt)
#### logistic regression ####

## Model 0
logreg0<- glm(LoanApproved ~ InterestRate + AutoLoanBalance + OtherInsurancePolicies + 
                      MonthlyHousingCosts + CreditCardUtilizationRate + PersonalLoanBalance,
                    data = train, family = binomial)
summary(logreg0)

## Model 1 

logreg1 <- glm(LoanApproved ~ CreditCardUtilizationRate + CreditScore + TotalAssets +
                 LoanAmount + MonthlySavings + Age, data = train, family = binomial)
summary(logreg1)


# running glm on each variable individually to check if they care good for model prediction

# CreditScore: lowered aic and deviance 
# variables significant to the 99%
logreg_i <-glm(LoanApproved ~ CreditScore, data = train, family = binomial)
summary(logreg_i)

# CreditCardUtilizationRate:lowered deviance slightly
# variables significant to the 90%
logreg_i <-glm(LoanApproved ~ CreditCardUtilizationRate, data = train, family = binomial)
summary(logreg_i)

# TotalAssets:lowered deviance slightly
# Not statistically significant
logreg_i <-glm(LoanApproved ~ TotalAssets, data = train, family = binomial)
summary(logreg_i)

# LoanAmount:didnt lower deviance or AIC
# variables insignificant
logreg_i <-glm(LoanApproved ~ LoanAmount, data = train, family = binomial)
summary(logreg_i)

# OtherInsurancePolicies:didnt lower deviance or AIC
# variables insignificant
logreg_i <-glm(LoanApproved ~ Age, data = train, family = binomial)
summary(logreg_i)

# MonthlySavings:lowered deviance slightly
# variables significant to the 90%
logreg_i <-glm(LoanApproved ~ MonthlySavings, data = train, family = binomial)
summary(logreg_i)


# based on these assessments, base model are:
# CreditCardUtilizationRate,CreditScore,TotalAssets, LengthOfCreditHistory, MonthlySavings
## Base Model

logreg2 <- glm(LoanApproved ~ CreditCardUtilizationRate + CreditScore + TotalAssets + 
                 LengthOfCreditHistory + MonthlySavings, data = train, family = binomial)
summary(logreg2)


## Deleting variables with large p-values
logreg3 <- glm(LoanApproved ~ CreditCardUtilizationRate + TotalAssets + CreditScore, data = train, family = binomial)
summary(logreg3)

## Adding Variables one by one, keeping if significant
logreg5 <- glm(LoanApproved ~ CreditCardUtilizationRate + CreditScore + EducationLevel+
                 AnnualIncome+ HomeOwnershipStatus+ TotalAssets , data = train, family = binomial)
summary(logreg5)

# this is the optimal model


#### Testing ####
loan.probs=predict(logreg5, newdata=test,type="response")
length(loan.probs)

loan.pred=rep(0,length(test))

loan.pred <- ifelse(loan.probs > 0.5, 1, 0)
loan.pred

table(loan.pred,test$LoanApproved) ->test.table
test.table

mean(loan.pred==test$LoanApproved)


#### Visualization ####
indices2 <- sample(1:75000, 1000)
train_plot <- train[indices2, ]

plot(LoanApproved~CreditScore, data=train_plot, main = 'LoanApproval to CreditScore')
plot(LoanApproved~AnnualIncome, data=train_plot, main = 'LoanApproval to AnnualIncome')


```

